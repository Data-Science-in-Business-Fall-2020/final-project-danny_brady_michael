{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in shark data\n",
    "eat = pd.read_excel(\"SharkData.xlsx\", sheet_name = 0)\n",
    "targets = pd.read_excel(\"SharkData.xlsx\", sheet_name = 1)\n",
    "drops = pd.read_excel(\"SharkData.xlsx\", sheet_name = 2)\n",
    "other_factors = pd.read_excel(\"SharkData.xlsx\", sheet_name = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ross</th>\n",
       "      <th>Chandler</th>\n",
       "      <th>BT1</th>\n",
       "      <th>BT2</th>\n",
       "      <th>BT3</th>\n",
       "      <th>BT4</th>\n",
       "      <th>BT5</th>\n",
       "      <th>GR1</th>\n",
       "      <th>GR2</th>\n",
       "      <th>GR3</th>\n",
       "      <th>GR4</th>\n",
       "      <th>GR5</th>\n",
       "      <th>Total</th>\n",
       "      <th>Etc. Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Ross  Chandler  BT1  BT2  BT3  BT4  BT5  GR1  GR2  GR3  GR4  \\\n",
       "0  2017-12-05   0.0       5.0  3.0  6.0  5.0  4.0  4.0  0.0  0.0  2.0  3.0   \n",
       "1  2017-12-07   1.0       0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  2017-12-09   NaN       NaN  NaN  NaN  NaN  NaN  NaN  2.0  0.0  3.0  1.0   \n",
       "3  2017-12-10   5.0       1.0  1.0  3.0  2.0  2.0  0.0  NaN  NaN  NaN  NaN   \n",
       "4  2017-12-12   2.0       2.0  0.0  5.0  2.0  4.0  5.0  0.0  2.0  3.0  2.0   \n",
       "\n",
       "   GR5  Total Etc. Comments  \n",
       "0  1.0   33.0           NaN  \n",
       "1  0.0    3.0           NaN  \n",
       "2  0.0    6.0           NaN  \n",
       "3  NaN   14.0           NaN  \n",
       "4  0.0   27.0           NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean eating dataset\n",
    "eat = eat.iloc[1:,:-1]\n",
    "eat.rename(columns = {\"Unnamed: 14\":'Etc. Comments', \"Pieces Eaten\": \"Date\", 'Total: ' : 'Total'}, inplace = True)\n",
    "\n",
    "#get rid of null values at end of dataset\n",
    "eat = eat.head(582)\n",
    "\n",
    "# Change date to just date format, not datetime\n",
    "eat['Date'] = pd.to_datetime(eat['Date']).dt.date\n",
    "\n",
    "\n",
    "\n",
    "eat.reset_index(drop=True,inplace = True)\n",
    "eat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ross</th>\n",
       "      <th>Chandler</th>\n",
       "      <th>BT1</th>\n",
       "      <th>BT2</th>\n",
       "      <th>BT3</th>\n",
       "      <th>BT4</th>\n",
       "      <th>BT5</th>\n",
       "      <th>GR1</th>\n",
       "      <th>GR2</th>\n",
       "      <th>GR3</th>\n",
       "      <th>GR4</th>\n",
       "      <th>GR5</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Ross  Chandler  BT1  BT2  BT3  BT4  BT5  GR1  GR2  GR3  GR4  \\\n",
       "577  2020-09-22   0.0       0.0  1.0  4.0  0.0  2.0  2.0  0.0  0.0  0.0  1.0   \n",
       "578  2020-09-24   0.0       0.0  0.0  3.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0   \n",
       "579  2020-09-26   NaN       NaN  NaN  NaN  NaN  NaN  NaN  0.0  0.0  0.0  0.0   \n",
       "580  2020-09-27   0.0       0.0  2.0  0.0  0.0  0.0  1.0  NaN  NaN  NaN  NaN   \n",
       "581  2020-09-29   0.0       0.0  0.0  2.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "     GR5  Total  \n",
       "577  0.0   10.0  \n",
       "578  0.0    7.0  \n",
       "579  1.0    1.0  \n",
       "580  NaN    3.0  \n",
       "581  0.0    4.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean Drops Dataset\n",
    "drops = drops.iloc[1:,:-1]\n",
    "drops['Drops'] = pd.to_datetime(drops['Drops']).dt.date\n",
    "drops.rename(columns = {\"Drops\" : \"Date\", \"Total: \":\"Total\"}, inplace = True)\n",
    "drops.reset_index(drop=True,inplace = True)\n",
    "drops.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ross</th>\n",
       "      <th>Chandler</th>\n",
       "      <th>BT1</th>\n",
       "      <th>BT2</th>\n",
       "      <th>BT3</th>\n",
       "      <th>BT4</th>\n",
       "      <th>BT5</th>\n",
       "      <th>GR1</th>\n",
       "      <th>GR2</th>\n",
       "      <th>GR3</th>\n",
       "      <th>GR4</th>\n",
       "      <th>GR5</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Ross  Chandler  BT1   BT2   BT3   BT4   BT5  GR1  GR2  GR3  \\\n",
       "577  2020-09-22   6.0       1.0  4.0   6.0   5.0   4.0   7.0  2.0  1.0  5.0   \n",
       "578  2020-09-24   8.0      18.0  2.0   9.0  10.0  10.0  11.0  5.0  6.0  3.0   \n",
       "579  2020-09-26   NaN       NaN  NaN   NaN   NaN   NaN   NaN  6.0  2.0  3.0   \n",
       "580  2020-09-27  10.0      19.0  9.0  10.0   8.0  16.0   3.0  NaN  NaN  NaN   \n",
       "581  2020-09-29  15.0       5.0  6.0   6.0   4.0   4.0   7.0  4.0  1.0  4.0   \n",
       "\n",
       "     GR4  GR5  Total  \n",
       "577  4.0  1.0   46.0  \n",
       "578  7.0  9.0   98.0  \n",
       "579  5.0  8.0   24.0  \n",
       "580  NaN  NaN   75.0  \n",
       "581  4.0  1.0   61.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean Targets Dataset\n",
    "targets = targets.iloc[1:,:-1]\n",
    "targets.rename(columns = {\"Unnamed: 14\":'Etc. Comments', \"Targets\": \"Date\", \"Total: \": \"Total\"}, inplace = True)\n",
    "\n",
    "#get rid of null values at end of dataset\n",
    "targets = targets.head(582)\n",
    "\n",
    "# Change date to just date format, not datetime\n",
    "targets['Date'] = pd.to_datetime(targets['Date']).dt.date\n",
    "\n",
    "targets.reset_index(drop=True,inplace = True)\n",
    "targets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Factors Data Cleaning and Dummy Variable Creation for Foods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sport10/.local/lib/python3.8/site-packages/pandas/core/frame.py:4295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "<ipython-input-57-456bd9ea25b4>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dummy_factors[i] = dummy_factors[i].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "dummy_factors = other_factors[['Saury', 'Blue Runner',\n",
    "                'Squid', 'Mackerel', 'Herring', 'Sardine',\n",
    "                'Mazuri Vitamins', 'Garlic', 'Salmon', 'Bonito', 'Bluefish', 'Mahi',\n",
    "                    'Goggle Eye', 'Humbolt Squid']]\n",
    "other_dummies = other_factors[['BT/SB Location (1-6)','GR Location (1-6)']]\n",
    "other_dummies.rename(columns= {\"BT/SB Location (1-6)\": \"BT_SB_Location\", \"GR Location (1-6)\": \"GR_Location\"}, inplace = True)\n",
    "for i in dummy_factors:\n",
    "    dummy_factors[i] = dummy_factors[i].fillna(0)\n",
    "dummy_factors.rename(columns = {\"Blue Runner\": \"Blue_Runner\", \"Mazuri Vitamins\": \"Mazuri_Vitamins\", \n",
    "                               \"Goggle Eye\": \"Goggle_Eye\", \"Humbolt Squid\": \"Humbolt_Squid\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Datasets to get all factors to perform regression on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add seasons variables\n",
    "def season_of_date(date):\n",
    "    date = pd.to_datetime(date)\n",
    "    year = str(date.year)\n",
    "    seasons = {'spring': pd.date_range(start=year+'/03/21', end=year+'/06/20'),\n",
    "               'summer': pd.date_range(start=year+'/06/21', end=year+'/09/22'),\n",
    "               'fall': pd.date_range(start=year+'/09/23', end=year+'/12/20')}\n",
    "    if date in seasons['spring']:\n",
    "        return 'spring'\n",
    "    if date in seasons['summer']:\n",
    "        return 'summer'\n",
    "    if date in seasons['fall']:\n",
    "        return 'fall'\n",
    "    else:\n",
    "        return 'winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-430957c61749>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_summer['summer'] = 1\n",
      "<ipython-input-59-430957c61749>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_summer['fall'] = 0\n",
      "<ipython-input-59-430957c61749>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_summer['spring'] = 0\n",
      "<ipython-input-59-430957c61749>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_fall['summer'] = 0\n",
      "<ipython-input-59-430957c61749>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_fall['fall'] = 1\n",
      "<ipython-input-59-430957c61749>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_fall['spring'] = 0\n",
      "<ipython-input-59-430957c61749>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_winter['summer'] = 0\n",
      "<ipython-input-59-430957c61749>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_winter['fall'] = 0\n",
      "<ipython-input-59-430957c61749>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_winter['spring'] = 0\n",
      "<ipython-input-59-430957c61749>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_spring['summer'] = 0\n",
      "<ipython-input-59-430957c61749>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_spring['fall'] = 0\n",
      "<ipython-input-59-430957c61749>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eat_spring['spring'] = 1\n"
     ]
    }
   ],
   "source": [
    "eat_summer = eat[eat.Date.map(season_of_date)==\"summer\"]\n",
    "eat_summer['summer'] = 1\n",
    "eat_summer['fall'] = 0\n",
    "eat_summer['spring'] = 0\n",
    "eat_fall = eat[eat.Date.map(season_of_date)==\"fall\"]\n",
    "eat_fall['summer'] = 0\n",
    "eat_fall['fall'] = 1\n",
    "eat_fall['spring'] = 0\n",
    "eat_winter = eat[eat.Date.map(season_of_date)==\"winter\"]\n",
    "eat_winter['summer'] = 0\n",
    "eat_winter['fall'] = 0\n",
    "eat_winter['spring'] = 0\n",
    "eat_spring = eat[eat.Date.map(season_of_date)==\"spring\"]\n",
    "eat_spring['summer'] = 0\n",
    "eat_spring['fall'] = 0\n",
    "eat_spring['spring'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "eat_all_seasons = pd.concat([eat_summer,eat_fall,eat_winter,eat_spring])\n",
    "eat_all_seasons_sort = eat_all_seasons.sort_values(by=[\"Date\"])\n",
    "eat_season_vars = eat_all_seasons_sort[['summer', 'fall', 'spring']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-8f5950c59aad>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_summer['summer'] = 1\n",
      "<ipython-input-61-8f5950c59aad>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_summer['fall'] = 0\n",
      "<ipython-input-61-8f5950c59aad>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_summer['spring'] = 0\n",
      "<ipython-input-61-8f5950c59aad>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_fall['summer'] = 0\n",
      "<ipython-input-61-8f5950c59aad>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_fall['fall'] = 1\n",
      "<ipython-input-61-8f5950c59aad>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_fall['spring'] = 0\n",
      "<ipython-input-61-8f5950c59aad>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_winter['summer'] = 0\n",
      "<ipython-input-61-8f5950c59aad>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_winter['fall'] = 0\n",
      "<ipython-input-61-8f5950c59aad>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_winter['spring'] = 0\n",
      "<ipython-input-61-8f5950c59aad>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_spring['summer'] = 0\n",
      "<ipython-input-61-8f5950c59aad>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_spring['fall'] = 0\n",
      "<ipython-input-61-8f5950c59aad>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drops_spring['spring'] = 1\n"
     ]
    }
   ],
   "source": [
    "drops_summer = drops[eat.Date.map(season_of_date)==\"summer\"]\n",
    "drops_summer['summer'] = 1\n",
    "drops_summer['fall'] = 0\n",
    "drops_summer['spring'] = 0\n",
    "drops_fall = drops[eat.Date.map(season_of_date)==\"fall\"]\n",
    "drops_fall['summer'] = 0\n",
    "drops_fall['fall'] = 1\n",
    "drops_fall['spring'] = 0\n",
    "drops_winter = drops[eat.Date.map(season_of_date)==\"winter\"]\n",
    "drops_winter['summer'] = 0\n",
    "drops_winter['fall'] = 0\n",
    "drops_winter['spring'] = 0\n",
    "drops_spring = drops[eat.Date.map(season_of_date)==\"spring\"]\n",
    "drops_spring['summer'] = 0\n",
    "drops_spring['fall'] = 0\n",
    "drops_spring['spring'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops_all_seasons = pd.concat([drops_summer,drops_fall,drops_winter,drops_spring])\n",
    "drops_all_seasons_sort = drops_all_seasons.sort_values(by=[\"Date\"])\n",
    "drops_season_vars = drops_all_seasons_sort[['summer', 'fall', 'spring']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-63-3a678d7c0e93>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_summer['summer'] = 1\n",
      "<ipython-input-63-3a678d7c0e93>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_summer['fall'] = 0\n",
      "<ipython-input-63-3a678d7c0e93>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_summer['spring'] = 0\n",
      "<ipython-input-63-3a678d7c0e93>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_fall['summer'] = 0\n",
      "<ipython-input-63-3a678d7c0e93>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_fall['fall'] = 1\n",
      "<ipython-input-63-3a678d7c0e93>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_fall['spring'] = 0\n",
      "<ipython-input-63-3a678d7c0e93>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_winter['summer'] = 0\n",
      "<ipython-input-63-3a678d7c0e93>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_winter['fall'] = 0\n",
      "<ipython-input-63-3a678d7c0e93>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_winter['spring'] = 0\n",
      "<ipython-input-63-3a678d7c0e93>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_spring['summer'] = 0\n",
      "<ipython-input-63-3a678d7c0e93>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_spring['fall'] = 0\n",
      "<ipython-input-63-3a678d7c0e93>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets_spring['spring'] = 1\n"
     ]
    }
   ],
   "source": [
    "targets_summer = targets[eat.Date.map(season_of_date)==\"summer\"]\n",
    "targets_summer['summer'] = 1\n",
    "targets_summer['fall'] = 0\n",
    "targets_summer['spring'] = 0\n",
    "targets_fall = targets[eat.Date.map(season_of_date)==\"fall\"]\n",
    "targets_fall['summer'] = 0\n",
    "targets_fall['fall'] = 1\n",
    "targets_fall['spring'] = 0\n",
    "targets_winter = targets[eat.Date.map(season_of_date)==\"winter\"]\n",
    "targets_winter['summer'] = 0\n",
    "targets_winter['fall'] = 0\n",
    "targets_winter['spring'] = 0\n",
    "targets_spring = targets[eat.Date.map(season_of_date)==\"spring\"]\n",
    "targets_spring['summer'] = 0\n",
    "targets_spring['fall'] = 0\n",
    "targets_spring['spring'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_all_seasons = pd.concat([targets_summer,targets_fall,targets_winter,targets_spring])\n",
    "targets_all_seasons_sort = targets_all_seasons.sort_values(by=[\"Date\"])\n",
    "targets_season_vars = targets_all_seasons_sort[['summer', 'fall', 'spring']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ross</th>\n",
       "      <th>Chandler</th>\n",
       "      <th>BT1</th>\n",
       "      <th>BT2</th>\n",
       "      <th>BT3</th>\n",
       "      <th>BT4</th>\n",
       "      <th>BT5</th>\n",
       "      <th>GR1</th>\n",
       "      <th>GR2</th>\n",
       "      <th>...</th>\n",
       "      <th>Bluefish</th>\n",
       "      <th>Mahi</th>\n",
       "      <th>Goggle_Eye</th>\n",
       "      <th>Humbolt_Squid</th>\n",
       "      <th>BT_SB_Location</th>\n",
       "      <th>GR_Location</th>\n",
       "      <th>summer</th>\n",
       "      <th>fall</th>\n",
       "      <th>spring</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Ross  Chandler  BT1  BT2  BT3  BT4  BT5  GR1  GR2  ...  \\\n",
       "0  2017-12-05   0.0       5.0  3.0  6.0  5.0  4.0  4.0  0.0  0.0  ...   \n",
       "1  2017-12-07   1.0       0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2  2017-12-09   NaN       NaN  NaN  NaN  NaN  NaN  NaN  2.0  0.0  ...   \n",
       "3  2017-12-10   5.0       1.0  1.0  3.0  2.0  2.0  0.0  NaN  NaN  ...   \n",
       "4  2017-12-12   2.0       2.0  0.0  5.0  2.0  4.0  5.0  0.0  2.0  ...   \n",
       "\n",
       "   Bluefish  Mahi  Goggle_Eye  Humbolt_Squid BT_SB_Location  GR_Location  \\\n",
       "0       0.0   0.0         0.0            0.0            1.0          3.0   \n",
       "1       0.0   0.0         0.0            0.0            1.0          3.0   \n",
       "2       0.0   0.0         0.0            0.0            NaN          3.0   \n",
       "3       0.0   0.0         0.0            0.0            1.0          NaN   \n",
       "4       0.0   0.0         0.0            0.0            1.0          3.0   \n",
       "\n",
       "   summer  fall  spring  Temperature  \n",
       "0       0     1       0         73.2  \n",
       "1       0     1       0         73.2  \n",
       "2       0     1       0         73.6  \n",
       "3       0     1       0         73.6  \n",
       "4       0     1       0         73.4  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine eat data\n",
    "eat_concat1 = pd.concat([eat,dummy_factors,other_dummies, eat_season_vars], axis = 1)\n",
    "eat_concat = pd.concat([eat_concat1, other_factors[\"Temperature\"]], axis = 1)\n",
    "eat_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GroupFeed = []\n",
    "for row in drops.index:\n",
    "    if drops.iloc[row,:].isna().sum() > 0:\n",
    "        GroupFeed.append(0)\n",
    "    else:\n",
    "        GroupFeed.append(1)\n",
    "GroupFeed\n",
    "\n",
    "#you could do something like this to add it to a dataframe\n",
    "#eat[\"GroupFeed\"] = GroupFeed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add eat variable for Covid shut down\n",
    "start_date = pd.to_datetime('03-14-2020')\n",
    "end_date = pd.to_datetime('05-09-2020')\n",
    "conditions = [ (eat_concat['Date'] >= start_date) & (eat_concat['Date'] <= end_date),\n",
    "              (eat_concat['Date'] < start_date) | (eat_concat['Date'] > end_date)]\n",
    "values = [1, 0]\n",
    "eat_concat[\"covid\"] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add eat variable for light training\n",
    "light_start = pd.to_datetime('02-15-2018')\n",
    "conditions_light = [ (eat_concat['Date'] >= light_start), (eat_concat['Date'] < light_start)]\n",
    "values_light = [1, 0]\n",
    "eat_concat[\"light_training\"] = np.select(conditions_light, values_light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ross</th>\n",
       "      <th>Chandler</th>\n",
       "      <th>BT1</th>\n",
       "      <th>BT2</th>\n",
       "      <th>BT3</th>\n",
       "      <th>BT4</th>\n",
       "      <th>BT5</th>\n",
       "      <th>GR1</th>\n",
       "      <th>GR2</th>\n",
       "      <th>...</th>\n",
       "      <th>Bluefish</th>\n",
       "      <th>Mahi</th>\n",
       "      <th>Goggle_Eye</th>\n",
       "      <th>Humbolt_Squid</th>\n",
       "      <th>BT_SB_Location</th>\n",
       "      <th>GR_Location</th>\n",
       "      <th>summer</th>\n",
       "      <th>fall</th>\n",
       "      <th>spring</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Ross  Chandler  BT1  BT2  BT3  BT4  BT5  GR1  GR2  ...  \\\n",
       "0  2017-12-05   0.0       0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   \n",
       "1  2017-12-07   0.0       1.0  1.0  2.0  1.0  1.0  2.0  0.0  0.0  ...   \n",
       "2  2017-12-09   NaN       NaN  NaN  NaN  NaN  NaN  NaN  0.0  1.0  ...   \n",
       "3  2017-12-10   0.0       0.0  0.0  0.0  0.0  0.0  1.0  NaN  NaN  ...   \n",
       "4  2017-12-12   0.0       0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "   Bluefish  Mahi  Goggle_Eye  Humbolt_Squid  BT_SB_Location  GR_Location  \\\n",
       "0       0.0   0.0         0.0            0.0             1.0          3.0   \n",
       "1       0.0   0.0         0.0            0.0             1.0          3.0   \n",
       "2       0.0   0.0         0.0            0.0             NaN          3.0   \n",
       "3       0.0   0.0         0.0            0.0             1.0          NaN   \n",
       "4       0.0   0.0         0.0            0.0             1.0          3.0   \n",
       "\n",
       "   summer  fall  spring  Temperature  \n",
       "0       0     1       0         73.2  \n",
       "1       0     1       0         73.2  \n",
       "2       0     1       0         73.6  \n",
       "3       0     1       0         73.6  \n",
       "4       0     1       0         73.4  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine drops data\n",
    "drops_concat1 = pd.concat([drops,dummy_factors,other_dummies, drops_season_vars], axis = 1)\n",
    "drops_concat = pd.concat([drops_concat1, other_factors[\"Temperature\"]], axis = 1)\n",
    "drops_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add drop variable for Covid shut down\n",
    "start_date = pd.to_datetime('03-14-2020')\n",
    "end_date = pd.to_datetime('05-09-2020')\n",
    "conditions = [ (drops_concat['Date'] >= start_date) & (drops_concat['Date'] <= end_date),\n",
    "              (drops_concat['Date'] < start_date) | (drops_concat['Date'] > end_date)]\n",
    "values = [1, 0]\n",
    "drops_concat[\"covid\"] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add drop variable for light training\n",
    "light_start = pd.to_datetime('02-15-2018')\n",
    "conditions_light = [ (drops_concat['Date'] >= light_start), (drops_concat['Date'] < light_start)]\n",
    "values_light = [1, 0]\n",
    "drops_concat[\"light_training\"] = np.select(conditions_light, values_light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ross</th>\n",
       "      <th>Chandler</th>\n",
       "      <th>BT1</th>\n",
       "      <th>BT2</th>\n",
       "      <th>BT3</th>\n",
       "      <th>BT4</th>\n",
       "      <th>BT5</th>\n",
       "      <th>GR1</th>\n",
       "      <th>GR2</th>\n",
       "      <th>...</th>\n",
       "      <th>Bluefish</th>\n",
       "      <th>Mahi</th>\n",
       "      <th>Goggle_Eye</th>\n",
       "      <th>Humbolt_Squid</th>\n",
       "      <th>BT_SB_Location</th>\n",
       "      <th>GR_Location</th>\n",
       "      <th>summer</th>\n",
       "      <th>fall</th>\n",
       "      <th>spring</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Ross  Chandler  BT1  BT2  BT3  BT4  BT5  GR1  GR2  ...  \\\n",
       "0  2017-12-05   3.0       0.0  4.0  3.0  0.0  2.0  2.0  1.0  1.0  ...   \n",
       "1  2017-12-07   4.0       5.0  2.0  2.0  5.0  3.0  5.0  0.0  0.0  ...   \n",
       "2  2017-12-09   NaN       NaN  NaN  NaN  NaN  NaN  NaN  1.0  3.0  ...   \n",
       "3  2017-12-10   4.0       7.0  0.0  2.0  2.0  0.0  0.0  NaN  NaN  ...   \n",
       "4  2017-12-12   3.0       1.0  3.0  2.0  4.0  1.0  1.0  1.0  1.0  ...   \n",
       "\n",
       "   Bluefish  Mahi  Goggle_Eye  Humbolt_Squid  BT_SB_Location  GR_Location  \\\n",
       "0       0.0   0.0         0.0            0.0             1.0          3.0   \n",
       "1       0.0   0.0         0.0            0.0             1.0          3.0   \n",
       "2       0.0   0.0         0.0            0.0             NaN          3.0   \n",
       "3       0.0   0.0         0.0            0.0             1.0          NaN   \n",
       "4       0.0   0.0         0.0            0.0             1.0          3.0   \n",
       "\n",
       "   summer  fall  spring  Temperature  \n",
       "0       0     1       0         73.2  \n",
       "1       0     1       0         73.2  \n",
       "2       0     1       0         73.6  \n",
       "3       0     1       0         73.6  \n",
       "4       0     1       0         73.4  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine Target data\n",
    "targets_concat1 = pd.concat([targets,dummy_factors,other_dummies, targets_season_vars], axis = 1)\n",
    "targets_concat = pd.concat([targets_concat1, other_factors[\"Temperature\"]], axis = 1)\n",
    "targets_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add target variable for Covid shut down\n",
    "start_date = pd.to_datetime('03-14-2020')\n",
    "end_date = pd.to_datetime('05-09-2020')\n",
    "conditions = [ (targets_concat['Date'] >= start_date) & (targets_concat['Date'] <= end_date),\n",
    "              (targets_concat['Date'] < start_date) | (targets_concat['Date'] > end_date)]\n",
    "values = [1, 0]\n",
    "targets_concat[\"covid\"] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add target variable for light training\n",
    "light_start = pd.to_datetime('02-15-2018')\n",
    "conditions_light = [ (targets_concat['Date'] >= light_start), (targets_concat['Date'] < light_start)]\n",
    "values_light = [1, 0]\n",
    "targets_concat[\"light_training\"] = np.select(conditions_light, values_light)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# All SS Subset\n",
    "All_SS = eat_concat[['Ross', 'Chandler']]\n",
    "\n",
    "# All BT Subset\n",
    "All_BT = eat_concat[['BT1', 'BT2', 'BT3', 'BT4', 'BT5']]\n",
    "\n",
    "# All GR Subset\n",
    "All_GR = eat_concat[['GR1', 'GR2', 'GR3', 'GR4', 'GR5']]\n",
    "\n",
    "# Male Subset\n",
    "Male = eat_concat[[\"BT1\",\"BT5\",\"GR1\",\"Ross\",\"Chandler\"]]\n",
    "\n",
    "# Female Subset\n",
    "female = eat_concat[[\"BT2\",\"BT3\",\"BT4\",\"GR2\",\"GR3\",\"GR4\",\"GR5\"]]\n",
    "\n",
    "# Append all subsets to original datasets\n",
    "# eat dataset\n",
    "eat_concat[\"All_GR\"] = eat['GR1'] + eat['GR2'] + eat['GR3'] + eat['GR4'] + eat['GR5']\n",
    "eat_concat[\"All_BT\"] = eat['BT1'] + eat['BT2'] + eat['BT3'] + eat['BT4'] + eat['BT5']\n",
    "eat_concat[\"All_SS\"] = eat['Ross'] + eat['Chandler']\n",
    "eat_concat[\"male\"] = eat[[\"BT1\",\"BT5\",\"GR1\",\"Ross\",\"Chandler\"]].sum(axis = 1)\n",
    "eat_concat[\"female\"] = eat[[\"BT2\",\"BT3\",\"BT4\",\"GR2\",\"GR3\",\"GR4\",\"GR5\"]].sum(axis = 1)\n",
    "\n",
    "# drop dataset\n",
    "drops_concat[\"All_GR\"] = drops['GR1'] + drops['GR2'] + drops['GR3'] + drops['GR4'] + drops['GR5']\n",
    "drops_concat[\"All_BT\"] = drops['BT1'] + drops['BT2'] + drops['BT3'] + drops['BT4'] + drops['BT5']\n",
    "drops_concat[\"All_SS\"] = drops['Ross'] + drops['Chandler']\n",
    "drops_concat[\"male\"] = drops[[\"BT1\",\"BT5\",\"GR1\",\"Ross\",\"Chandler\"]].sum(axis = 1)\n",
    "drops_concat[\"female\"] = drops[[\"BT2\",\"BT3\",\"BT4\",\"GR2\",\"GR3\",\"GR4\",\"GR5\"]].sum(axis = 1)\n",
    "\n",
    "# target dataset\n",
    "targets_concat[\"All_GR\"] = targets['GR1'] + targets['GR2'] + targets['GR3'] + targets['GR4'] + targets['GR5']\n",
    "targets_concat[\"All_BT\"] = targets['BT1'] + targets['BT2'] + targets['BT3'] + targets['BT4'] + targets['BT5']\n",
    "targets_concat[\"All_SS\"] = targets['Ross'] + targets['Chandler']\n",
    "targets_concat[\"male\"] = targets[[\"BT1\",\"BT5\",\"GR1\",\"Ross\",\"Chandler\"]].sum(axis = 1)\n",
    "targets_concat[\"female\"] = targets[[\"BT2\",\"BT3\",\"BT4\",\"GR2\",\"GR3\",\"GR4\",\"GR5\"]].sum(axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tables for Poisson Regression Time Series For Pieces Eaten For All Sharks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ross</th>\n",
       "      <th>Chandler</th>\n",
       "      <th>BT1</th>\n",
       "      <th>BT2</th>\n",
       "      <th>BT3</th>\n",
       "      <th>BT4</th>\n",
       "      <th>BT5</th>\n",
       "      <th>GR1</th>\n",
       "      <th>GR2</th>\n",
       "      <th>...</th>\n",
       "      <th>covid</th>\n",
       "      <th>light_training</th>\n",
       "      <th>All_GR</th>\n",
       "      <th>All_BT</th>\n",
       "      <th>All_SS</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Ross  Chandler  BT1  BT2  BT3  BT4  BT5  GR1  GR2  ...  covid  \\\n",
       "0 2017-12-05   0.0       5.0  3.0  6.0  5.0  4.0  4.0  0.0  0.0  ...      0   \n",
       "1 2017-12-07   1.0       0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  ...      0   \n",
       "2 2017-12-09   NaN       NaN  NaN  NaN  NaN  NaN  NaN  2.0  0.0  ...      0   \n",
       "3 2017-12-10   5.0       1.0  1.0  3.0  2.0  2.0  0.0  NaN  NaN  ...      0   \n",
       "4 2017-12-12   2.0       2.0  0.0  5.0  2.0  4.0  5.0  0.0  2.0  ...      0   \n",
       "\n",
       "   light_training  All_GR  All_BT All_SS  male  female  Day_of_week  Month  \\\n",
       "0               0     6.0    22.0    5.0  12.0    21.0            1     12   \n",
       "1               0     0.0     2.0    1.0   1.0     2.0            3     12   \n",
       "2               0     6.0     NaN    NaN   2.0     4.0            5     12   \n",
       "3               0     NaN     8.0    6.0   7.0     7.0            6     12   \n",
       "4               0     7.0    16.0    4.0   9.0    18.0            1     12   \n",
       "\n",
       "   Day  \n",
       "0    5  \n",
       "1    7  \n",
       "2    9  \n",
       "3   10  \n",
       "4   12  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create additional time variables for eating\n",
    "eat_concat['Date'] = pd.to_datetime(eat_concat['Date'])\n",
    "eat_concat['Day_of_week'] = pd.to_datetime(eat_concat['Date']).dt.dayofweek\n",
    "eat_concat['Month'] = pd.to_datetime(eat_concat['Date']).dt.month\n",
    "eat_concat['Day'] = pd.to_datetime(eat_concat['Date']).dt.day\n",
    "eat_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set length=474\n",
      "Testing data set length=108\n"
     ]
    }
   ],
   "source": [
    "# Create training and testing datasets\n",
    "mask = np.random.rand(len(eat_concat)) < 0.8\n",
    "eat_train = eat_concat[mask]\n",
    "eat_test = eat_concat[~mask]\n",
    "print('Training data set length='+str(len(eat_train)))\n",
    "print('Testing data set length='+str(len(eat_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Saury</th>\n",
       "      <th>Blue_Runner</th>\n",
       "      <th>Squid</th>\n",
       "      <th>Mackerel</th>\n",
       "      <th>Herring</th>\n",
       "      <th>Sardine</th>\n",
       "      <th>Mazuri_Vitamins</th>\n",
       "      <th>Garlic</th>\n",
       "      <th>Salmon</th>\n",
       "      <th>...</th>\n",
       "      <th>Goggle_Eye</th>\n",
       "      <th>Humbolt_Squid</th>\n",
       "      <th>BT_SB_Location</th>\n",
       "      <th>GR_Location</th>\n",
       "      <th>summer</th>\n",
       "      <th>fall</th>\n",
       "      <th>spring</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>covid</th>\n",
       "      <th>light_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total  Saury  Blue_Runner  Squid  Mackerel  Herring  Sardine  \\\n",
       "0     33.0    1.0          0.0    0.0       0.0      0.0      0.0   \n",
       "1      3.0    0.0          1.0    1.0       1.0      0.0      0.0   \n",
       "2      6.0    0.0          0.0    0.0       0.0      1.0      0.0   \n",
       "3     14.0    0.0          0.0    0.0       1.0      0.0      1.0   \n",
       "4     27.0    1.0          0.0    0.0       0.0      0.0      0.0   \n",
       "..     ...    ...          ...    ...       ...      ...      ...   \n",
       "577   26.0    1.0          0.0    0.0       0.0      0.0      0.0   \n",
       "578   44.0    0.0          1.0    1.0       0.0      0.0      0.0   \n",
       "579   12.0    0.0          0.0    0.0       0.0      1.0      0.0   \n",
       "580   33.0    0.0          0.0    0.0       1.0      0.0      1.0   \n",
       "581   38.0    1.0          0.0    0.0       0.0      0.0      0.0   \n",
       "\n",
       "     Mazuri_Vitamins  Garlic  Salmon  ...  Goggle_Eye  Humbolt_Squid  \\\n",
       "0                1.0     1.0     0.0  ...         0.0            0.0   \n",
       "1                1.0     1.0     0.0  ...         0.0            0.0   \n",
       "2                0.0     1.0     0.0  ...         0.0            0.0   \n",
       "3                0.0     1.0     0.0  ...         0.0            0.0   \n",
       "4                1.0     1.0     0.0  ...         0.0            0.0   \n",
       "..               ...     ...     ...  ...         ...            ...   \n",
       "577              1.0     1.0     0.0  ...         0.0            0.0   \n",
       "578              1.0     1.0     0.0  ...         0.0            0.0   \n",
       "579              0.0     0.0     0.0  ...         0.0            0.0   \n",
       "580              0.0     1.0     0.0  ...         0.0            0.0   \n",
       "581              1.0     1.0     0.0  ...         0.0            0.0   \n",
       "\n",
       "     BT_SB_Location  GR_Location  summer  fall  spring  Temperature  covid  \\\n",
       "0               1.0          3.0       0     1       0         73.2      0   \n",
       "1               1.0          3.0       0     1       0         73.2      0   \n",
       "2               NaN          3.0       0     1       0         73.6      0   \n",
       "3               1.0          NaN       0     1       0         73.6      0   \n",
       "4               1.0          3.0       0     1       0         73.4      0   \n",
       "..              ...          ...     ...   ...     ...          ...    ...   \n",
       "577             2.0          1.0       1     0       0         75.6      0   \n",
       "578             4.0          2.0       0     1       0         75.6      0   \n",
       "579             NaN          3.0       0     1       0         75.0      0   \n",
       "580             3.0          NaN       0     1       0         75.6      0   \n",
       "581             1.0          4.0       0     1       0         75.4      0   \n",
       "\n",
       "     light_training  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "..              ...  \n",
       "577               1  \n",
       "578               1  \n",
       "579               1  \n",
       "580               1  \n",
       "581               1  \n",
       "\n",
       "[582 rows x 23 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eat_concat.iloc[:,13:-8].drop(columns = \"Etc. Comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x contains NaN or inf values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-017fe6b4cbcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import for Granger's Causality Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstattools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgrangercausalitytests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgranger_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstattools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrangercausalitytests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meat_concat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Etc. Comments\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgranger_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py\u001b[0m in \u001b[0;36mgrangercausalitytests\u001b[0;34m(x, maxlag, addconst, verbose)\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x contains NaN or inf values.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m     \u001b[0maddconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"addconst\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"verbose\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x contains NaN or inf values."
     ]
    }
   ],
   "source": [
    "# import for Granger's Causality Test\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "granger_test = sm.tsa.stattools.grangercausalitytests(eat_concat.iloc[:,13:-8].drop(columns = \"Etc. Comments\"), maxlag=2, verbose=True)\n",
    "granger_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 20\n",
    "df_train, df_test = eat_concat.iloc[:,14:-8].drop(columns = \"Etc. Comments\")[0:-nobs], eat_concat.iloc[:,14:-8].drop(columns = \"Etc. Comments\")[-nobs:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic         -7.501681e+00\n",
      "p-value                 4.237286e-11\n",
      "# Lags                  7.000000e+00\n",
      "# Observations          5.540000e+02\n",
      "Critical Value (1%)    -3.442209e+00\n",
      "Critical Value (5%)    -2.866771e+00\n",
      "Critical Value (10%)   -2.569556e+00\n",
      "dtype: float64\n",
      "0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      1.0\n",
      "      ... \n",
      "557    1.0\n",
      "558    0.0\n",
      "559    0.0\n",
      "560    0.0\n",
      "561    1.0\n",
      "Name: Saury, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic           -4.085730\n",
      "p-value                   0.001022\n",
      "# Lags                    8.000000\n",
      "# Observations          553.000000\n",
      "Critical Value (1%)      -3.442230\n",
      "Critical Value (5%)      -2.866781\n",
      "Critical Value (10%)     -2.569561\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      1.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "557    0.0\n",
      "558    1.0\n",
      "559    0.0\n",
      "560    0.0\n",
      "561    0.0\n",
      "Name: Blue_Runner, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic           -4.899331\n",
      "p-value                   0.000035\n",
      "# Lags                   11.000000\n",
      "# Observations          550.000000\n",
      "Critical Value (1%)      -3.442296\n",
      "Critical Value (5%)      -2.866809\n",
      "Critical Value (10%)     -2.569576\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      1.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "557    0.0\n",
      "558    1.0\n",
      "559    0.0\n",
      "560    0.0\n",
      "561    0.0\n",
      "Name: Squid, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic           -5.000221\n",
      "p-value                   0.000022\n",
      "# Lags                   10.000000\n",
      "# Observations          551.000000\n",
      "Critical Value (1%)      -3.442274\n",
      "Critical Value (5%)      -2.866800\n",
      "Critical Value (10%)     -2.569571\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      1.0\n",
      "2      0.0\n",
      "3      1.0\n",
      "4      0.0\n",
      "      ... \n",
      "557    0.0\n",
      "558    0.0\n",
      "559    0.0\n",
      "560    1.0\n",
      "561    0.0\n",
      "Name: Mackerel, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic           -4.050261\n",
      "p-value                   0.001169\n",
      "# Lags                   15.000000\n",
      "# Observations          546.000000\n",
      "Critical Value (1%)      -3.442384\n",
      "Critical Value (5%)      -2.866848\n",
      "Critical Value (10%)     -2.569597\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      1.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "557    0.0\n",
      "558    0.0\n",
      "559    1.0\n",
      "560    0.0\n",
      "561    0.0\n",
      "Name: Herring, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic         -5.724118e+00\n",
      "p-value                 6.833677e-07\n",
      "# Lags                  7.000000e+00\n",
      "# Observations          5.540000e+02\n",
      "Critical Value (1%)    -3.442209e+00\n",
      "Critical Value (5%)    -2.866771e+00\n",
      "Critical Value (10%)   -2.569556e+00\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      1.0\n",
      "4      0.0\n",
      "      ... \n",
      "557    0.0\n",
      "558    0.0\n",
      "559    0.0\n",
      "560    1.0\n",
      "561    0.0\n",
      "Name: Sardine, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic         -6.080132e+00\n",
      "p-value                 1.097254e-07\n",
      "# Lags                  7.000000e+00\n",
      "# Observations          5.540000e+02\n",
      "Critical Value (1%)    -3.442209e+00\n",
      "Critical Value (5%)    -2.866771e+00\n",
      "Critical Value (10%)   -2.569556e+00\n",
      "dtype: float64\n",
      "0      1.0\n",
      "1      1.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      1.0\n",
      "      ... \n",
      "557    1.0\n",
      "558    1.0\n",
      "559    0.0\n",
      "560    0.0\n",
      "561    1.0\n",
      "Name: Mazuri_Vitamins, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic           -4.696674\n",
      "p-value                   0.000085\n",
      "# Lags                   15.000000\n",
      "# Observations          546.000000\n",
      "Critical Value (1%)      -3.442384\n",
      "Critical Value (5%)      -2.866848\n",
      "Critical Value (10%)     -2.569597\n",
      "dtype: float64\n",
      "0      1.0\n",
      "1      1.0\n",
      "2      1.0\n",
      "3      1.0\n",
      "4      1.0\n",
      "      ... \n",
      "557    1.0\n",
      "558    1.0\n",
      "559    0.0\n",
      "560    1.0\n",
      "561    1.0\n",
      "Name: Garlic, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic           -2.399219\n",
      "p-value                   0.141957\n",
      "# Lags                   15.000000\n",
      "# Observations          546.000000\n",
      "Critical Value (1%)      -3.442384\n",
      "Critical Value (5%)      -2.866848\n",
      "Critical Value (10%)     -2.569597\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "557    0.0\n",
      "558    0.0\n",
      "559    0.0\n",
      "560    0.0\n",
      "561    0.0\n",
      "Name: Salmon, Length: 562, dtype: float64  Series is Non-Stationary\n",
      "Test Statistic           -4.297277\n",
      "p-value                   0.000449\n",
      "# Lags                   15.000000\n",
      "# Observations          546.000000\n",
      "Critical Value (1%)      -3.442384\n",
      "Critical Value (5%)      -2.866848\n",
      "Critical Value (10%)     -2.569597\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "557    0.0\n",
      "558    0.0\n",
      "559    0.0\n",
      "560    0.0\n",
      "561    0.0\n",
      "Name: Bonito, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic          -24.031862\n",
      "p-value                   0.000000\n",
      "# Lags                    0.000000\n",
      "# Observations          561.000000\n",
      "Critical Value (1%)      -3.442060\n",
      "Critical Value (5%)      -2.866706\n",
      "Critical Value (10%)     -2.569521\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "557    0.0\n",
      "558    0.0\n",
      "559    0.0\n",
      "560    0.0\n",
      "561    0.0\n",
      "Name: Bluefish, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic           -4.691592\n",
      "p-value                   0.000087\n",
      "# Lags                   15.000000\n",
      "# Observations          546.000000\n",
      "Critical Value (1%)      -3.442384\n",
      "Critical Value (5%)      -2.866848\n",
      "Critical Value (10%)     -2.569597\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "557    0.0\n",
      "558    0.0\n",
      "559    0.0\n",
      "560    0.0\n",
      "561    0.0\n",
      "Name: Mahi, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic           -3.799763\n",
      "p-value                   0.002910\n",
      "# Lags                   17.000000\n",
      "# Observations          544.000000\n",
      "Critical Value (1%)      -3.442428\n",
      "Critical Value (5%)      -2.866868\n",
      "Critical Value (10%)     -2.569607\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "557    0.0\n",
      "558    0.0\n",
      "559    0.0\n",
      "560    0.0\n",
      "561    0.0\n",
      "Name: Goggle_Eye, Length: 562, dtype: float64  Series is Stationary\n",
      "Test Statistic           -4.108458\n",
      "p-value                   0.000938\n",
      "# Lags                   14.000000\n",
      "# Observations          547.000000\n",
      "Critical Value (1%)      -3.442361\n",
      "Critical Value (5%)      -2.866838\n",
      "Critical Value (10%)     -2.569592\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "557    0.0\n",
      "558    0.0\n",
      "559    0.0\n",
      "560    0.0\n",
      "561    0.0\n",
      "Name: Humbolt_Squid, Length: 562, dtype: float64  Series is Stationary\n"
     ]
    },
    {
     "ename": "MissingDataError",
     "evalue": "exog contains inf or nans",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingDataError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-10ed82ff4dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#apply adf test on the series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0madf_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-89-10ed82ff4dd9>\u001b[0m in \u001b[0;36madf_test\u001b[0;34m(ts, signif)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstattools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madfuller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madf_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignif\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdftest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madfuller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautolag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AIC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0madf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdftest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Test Statistic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'p-value'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'# Lags'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'# Observations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdftest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py\u001b[0m in \u001b[0;36madfuller\u001b[0;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mregresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             icbest, bestlag = _autolag(\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mOLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxdshort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullRHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautolag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py\u001b[0m in \u001b[0;36m_autolag\u001b[0;34m(mod, endog, exog, startlag, maxlag, method, modargs, fitargs, regresults)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartlag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmaxlag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mmod_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    870\u001b[0m     def __init__(self, endog, exog=None, missing='none', hasconst=None,\n\u001b[1;32m    871\u001b[0m                  **kwargs):\n\u001b[0;32m--> 872\u001b[0;31m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[1;32m    873\u001b[0m                                   hasconst=hasconst, **kwargs)\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"weights\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[1;32m    704\u001b[0m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[1;32m    705\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pinv_wexog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'missing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hasconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0m\u001b[1;32m     78\u001b[0m                                       **kwargs)\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0m\u001b[1;32m    673\u001b[0m                  **kwargs)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconst_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasconst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m_handle_constant\u001b[0;34m(self, hasconst)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mexog_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mMissingDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exog contains inf or nans'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mexog_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mconst_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog_max\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexog_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingDataError\u001b[0m: exog contains inf or nans"
     ]
    }
   ],
   "source": [
    "# Augmented Dickey-Fuller Test (ADF Test)/unit root test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "def adf_test(ts, signif=0.05):\n",
    "    dftest = adfuller(ts, autolag='AIC')\n",
    "    adf = pd.Series(dftest[0:4], index=['Test Statistic','p-value','# Lags','# Observations'])\n",
    "    for key,value in dftest[4].items():\n",
    "        adf['Critical Value (%s)'%key] = value\n",
    "    print (adf)\n",
    "    \n",
    "    p = adf['p-value']\n",
    "    if p <= signif:\n",
    "        print(ts,f\" Series is Stationary\")\n",
    "    else:\n",
    "        print(ts,f\" Series is Non-Stationary\")\n",
    "#apply adf test on the series\n",
    "for i in df_train.columns:\n",
    "    adf_test(df_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Saury', 'Blue_Runner', 'Squid', 'Mackerel', 'Herring', 'Sardine',\n",
       "       'Mazuri_Vitamins', 'Garlic', 'Salmon', 'Bonito', 'Bluefish', 'Mahi',\n",
       "       'Goggle_Eye', 'Humbolt_Squid', 'BT_SB_Location', 'GR_Location',\n",
       "       'summer', 'fall', 'spring', 'Temperature', 'covid', 'light_training'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
